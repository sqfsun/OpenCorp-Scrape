{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"C:\\Users\\SQF\\跑着玩\\UEN\\UEN.xlsx\", sheet_name='Sheet1')\n",
    "UEN = df['UEN']\n",
    "url=[]\n",
    "str1=\"https://opencorpdata.com/sg/\"\n",
    "for uen in UEN:\n",
    "    url.append(str1+uen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Table = pd.DataFrame(columns=['UEN','Entity Name','Entity Status','Street Address','UEN Issue Date','Entity Type',\n",
    "                              'Incorporation Date','Account Due Date','Annual Return Date','Number Charges',\n",
    "                              'Primary SSIC Code','Primary SSIC Description','Secondary SSIC Code','Secondary SSIC Description',\n",
    "                              'Number Officers','Former Entity Name 1','Former Entity Name 2','Telephone'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>Entity Name</th>\n",
       "      <th>Entity Status</th>\n",
       "      <th>Street Address</th>\n",
       "      <th>UEN Issue Date</th>\n",
       "      <th>Entity Type</th>\n",
       "      <th>Incorporation Date</th>\n",
       "      <th>Account Due Date</th>\n",
       "      <th>Annual Return Date</th>\n",
       "      <th>Number Charges</th>\n",
       "      <th>Primary SSIC Code</th>\n",
       "      <th>Primary SSIC Description</th>\n",
       "      <th>Secondary SSIC Code</th>\n",
       "      <th>Secondary SSIC Description</th>\n",
       "      <th>Number Officers</th>\n",
       "      <th>Former Entity Name 1</th>\n",
       "      <th>Former Entity Name 2</th>\n",
       "      <th>Telephone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [UEN, Entity Name, Entity Status, Street Address, UEN Issue Date, Entity Type, Incorporation Date, Account Due Date, Annual Return Date, Number Charges, Primary SSIC Code, Primary SSIC Description, Secondary SSIC Code, Secondary SSIC Description, Number Officers, Former Entity Name 1, Former Entity Name 2, Telephone]\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(url)):\n",
    "    #specify the url\n",
    "    wiki = url[i]\n",
    "    #Query the website and return the html to the variable 'page'\n",
    "    try:\n",
    "        page = urlopen(wiki)\n",
    "\n",
    "        #import the Beautiful soup functions to parse the data returned from the website\n",
    "\n",
    "        #Parse the html in the 'page' variable, and store it in Beautiful Soup format\n",
    "        soup = BeautifulSoup(page,\"lxml\")\n",
    "\n",
    "        right_table=soup.find('table', class_='table table-striped table-hover table-dl')\n",
    "\n",
    "\n",
    "    \n",
    "        for row in right_table.findAll(\"tr\"):\n",
    "            if row.findAll('td')[0].find(text=True)=='Unique Entity Number (UEN)':\n",
    "                Table.loc[i,'UEN']=row.findAll('td')[1].find(text=True).strip('\\n\\r\\t\": ')\n",
    "            if row.findAll('td')[0].find(text=True)=='Entity Name':\n",
    "                Table.loc[i,'Entity Name']=row.findAll('td')[1].find(text=True).strip('\\n\\r\\t\": ')\n",
    "            if row.findAll('td')[0].find(text=True)=='Entity Status':\n",
    "                Table.loc[i,'Entity Status']=row.findAll('td')[1].find(text=True).strip('\\n\\r\\t\": ')\n",
    "            if row.findAll('td')[0].find(text=True)=='Street Address':\n",
    "                Table.loc[i,'Street Address']=row.findAll('td')[1].text.strip('\\n\\r\\t\": ')\n",
    "            if row.findAll('td')[0].find(text=True)=='UEN Issue Date':\n",
    "                Table.loc[i,'UEN Issue Date']=row.findAll('td')[1].find(text=True).strip('\\n\\r\\t\": ')\n",
    "            if row.findAll('td')[0].find(text=True)=='Entity Type':\n",
    "                Table.loc[i,'Entity Type']=row.findAll('td')[1].find(text=True).strip('\\n\\r\\t\": ')     \n",
    "            if row.findAll('td')[0].find(text=True)=='Incorporation Date':\n",
    "                Table.loc[i,'Incorporation Date']=row.findAll('td')[1].find(text=True).strip('\\n\\r\\t\": ')\n",
    "            if row.findAll('td')[0].find(text=True)=='Account Due Date':\n",
    "                Table.loc[i,'Account Due Date']=row.findAll('td')[1].find(text=True).strip('\\n\\r\\t\": ')\n",
    "            if row.findAll('td')[0].find(text=True)=='Annual Return Date':\n",
    "                Table.loc[i,'Annual Return Date']=row.findAll('td')[1].find(text=True).strip('\\n\\r\\t\": ')\n",
    "            if row.findAll('td')[0].find(text=True)=='Number Charges':\n",
    "                Table.loc[i,'Number Charges']=row.findAll('td')[1].find(text=True).strip('\\n\\r\\t\": ')\n",
    "            if row.findAll('td')[0].find(text=True)=='Primary SSIC Code':\n",
    "                Table.loc[i,'Primary SSIC Code']=row.findAll('td')[1].find(text=True).strip('\\n\\r\\t\": ')\n",
    "            if row.findAll('td')[0].find(text=True)=='Primary SSIC Description':\n",
    "                Table.loc[i,'Primary SSIC Description']=row.findAll('td')[1].find(text=True).strip('\\n\\r\\t\": ')\n",
    "            if row.findAll('td')[0].find(text=True)=='Secondary SSIC Code':\n",
    "                Table.loc[i,'Secondary SSIC Code']=row.findAll('td')[1].find(text=True).strip('\\n\\r\\t\": ')\n",
    "            if row.findAll('td')[0].find(text=True)=='Secondary SSIC Description':\n",
    "                Table.loc[i,'Secondary SSIC Description']=row.findAll('td')[1].find(text=True).strip('\\n\\r\\t\": ')\n",
    "            if row.findAll('td')[0].find(text=True)=='Number Officers':\n",
    "                Table.loc[i,'Number Officers']=row.findAll('td')[1].find(text=True).strip('\\n\\r\\t\": ')\n",
    "            if row.findAll('td')[0].find(text=True)=='Former Entity Name 1':\n",
    "                Table.loc[i,'Former Entity Name 1']=row.findAll('td')[1].find(text=True).strip('\\n\\r\\t\": ')\n",
    "            if row.findAll('td')[0].find(text=True)=='Former Entity Name 2':\n",
    "                Table.loc[i,'Former Entity Name 2']=row.findAll('td')[1].find(text=True).strip('\\n\\r\\t\": ')\n",
    "            if row.findAll('td')[0].find(text=True)=='Telephone':\n",
    "                Table.loc[i,'Telephone']=row.findAll('td')[1].find(text=True).strip('\\n\\r\\t\": ')\n",
    "        \n",
    "        print(i)\n",
    "        time.sleep(1)\n",
    "        #Table.to_csv(fileout,sep=',')\n",
    "    except:\n",
    "        print(i+\"_passed\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile=open('output.csv','w')\n",
    "Table.to_csv(outfile,mode='w',index=False)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('UENoutput.xlsx')\n",
    "Table.to_excel(writer, 'DataFrame')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
